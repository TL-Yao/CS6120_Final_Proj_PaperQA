import os
import json
import glob
import time
import requests
from tqdm import tqdm
from lxml import etree

import config

GROBID_URL = config.PDF_PROCESSOR_GROBID_URL
GROBID_DELAY = config.PDF_PROCESSOR_GROBID_API_CALL_DELAY_TIME_IN_SECONDS
PARAGRAPH_THRESHOLD = config.PDF_PROCESSOR_MIN_CHARACTER_CHUNK_THRESHOLD
BASE_PATH = config.RAW_DATA_PATH


def parse_academic_paper_grobid(pdf_path, grobid_url=GROBID_URL):
    """
    Parses an academic paper (PDF file) using GROBID and saves the resulting TEI XML file
    to the same directory as the PDF.
    
    Parameters:
        pdf_path (str): Full path to the PDF file.
        grobid_url (str): URL of the GROBID API endpoint. Defaults to the full-text endpoint.
        
    Returns:
        None
    """
    if not os.path.isfile(pdf_path):
        print(f"File {pdf_path} does not exist.")
        return

    try:
        with open(pdf_path, "rb") as pdf_file:
            files = {"input": pdf_file}
            response = requests.post(grobid_url, files=files)
    except Exception as e:
        print(f"Error connecting to the GROBID service or reading the file: {e}")
        return

    if response.status_code == 200:
        base_name = os.path.splitext(pdf_path)[0]
        output_path = base_name + ".xml"
        try:
            with open(output_path, "w", encoding="utf-8") as xml_file:
                xml_file.write(response.text)
            print(f"Parsing successful. XML file saved at: {output_path}")
        except Exception as e:
            print(f"Error writing the XML file: {e}")
    else:
        print(f"Parsing failed with status code: {response.status_code}")
        print(response.text)

def parse_tei_sections(xml_path):
    """
    Parses the TEI XML file and extracts first-level section information from the <body> element.
    For each section, returns a dictionary with:
        - 'title': Text of the <head> element (if available) or "Untitled Section"
        - 'content': Combined text from all <p> elements within that section.
    
    Parameters:
        xml_path (str): Full path to the TEI XML file generated by GROBID.
        
    Returns:
        list: A list of dictionaries representing the sections of the document.
    """
    if not os.path.isfile(xml_path):
        print(f"XML file {xml_path} does not exist.")
        return []

    try:
        # Remove extra whitespace for robustness
        parser = etree.XMLParser(remove_blank_text=True)
        tree = etree.parse(xml_path, parser)
    except Exception as e:
        print(f"Error parsing XML file {xml_path}: {e}")
        return []

    root = tree.getroot()
    ns = {'tei': 'http://www.tei-c.org/ns/1.0'}

    # Locate the <body> element, usually within <text><body>
    body = root.find('.//tei:text/tei:body', ns)
    if body is None:
        print("No <body> element found in the TEI XML.")
        return []

    sections = []
    # Extract only the first-level <div> elements (no recursive extraction)
    for div in body.findall('tei:div', ns):
        head_elem = div.find('tei:head', ns)
        title = head_elem.text.strip() if head_elem is not None and head_elem.text else "Untitled Section"
        # remove non-ascii characters and extra spaces
        paragraphs = [
            ''.join(p.itertext()).strip() 
            for p in div.findall('tei:p', ns) 
            if ''.join(p.itertext()).strip()
        ]
        content = " ".join(paragraphs)
        # skip empty content and too short paragraphs
        if not content.strip() or len(content.strip()) < PARAGRAPH_THRESHOLD:
            continue
        sections.append({
            "title": title,
            "content": content
        })
    return sections

def save_sections_as_json(sections, output_path):
    """
    Saves the extracted section hierarchy as a JSON file.
    
    Parameters:
        sections (list): List of section dictionaries extracted from the TEI XML.
        output_path (str): Full path to save the JSON file.
    """
    try:
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(sections, f, ensure_ascii=False, indent=4)
        print(f"Section data saved as JSON at: {output_path}")
    except Exception as e:
        print(f"Error saving JSON file: {e}")

if __name__ == "__main__":
    # Recursively search for all PDF files in the specified directory
    paper_pdf_paths = glob.glob(os.path.join(BASE_PATH, "**", "*.pdf"), recursive=True)
    
    for paper_pdf_path in tqdm(paper_pdf_paths):
        try:
            # Parse the PDF using GROBID to produce an XML file
            base_name = os.path.splitext(paper_pdf_path)[0]
            xml_output_path = base_name + ".xml"
            json_output_path = base_name + ".json"

            # skip if json parse alreay exists
            if os.path.exists(json_output_path):
                tqdm.write(f"skipping {paper_pdf_path}")
                continue
            
            # otherweise, start to parse grobid xml
            parse_academic_paper_grobid(paper_pdf_path)
            
            # Extract sections from the generated XML file
            sections = parse_tei_sections(xml_output_path)
            if sections:
                save_sections_as_json(sections, json_output_path)
            else:
                print(f"Failed to extract sections from {xml_output_path}.")
            
            # Sleep to avoid sending requests too rapidly
            time.sleep(GROBID_DELAY)
        except Exception as e:
            print(f"Error {e}")
       